{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT4T3JFK9Wtu",
        "outputId": "70602bf9-5262-4f45-8e74-821078432eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.10/dist-packages (0.5.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4222 files [02:51, 24.63 files/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2952 images belonging to 7 classes.\n",
            "Found 1270 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/ig_game_train_set'\n",
        "\n",
        "output_folder = '/content/'\n",
        "\n",
        "splitfolders.ratio(input_folder,\n",
        "                   output=output_folder,\n",
        "                   seed = 42,\n",
        "                   ratio = (.7, .0, .3))\n",
        "\n",
        "train = ImageDataGenerator(rescale= 1./255)\n",
        "val = ImageDataGenerator(rescale= 1./255)\n",
        "test = ImageDataGenerator(rescale= 1./255)\n",
        "\n",
        "train_dataset = train.flow_from_directory(\"/content/train\",\n",
        "                                          target_size= (150, 150),\n",
        "                                          batch_size= 32,\n",
        "                                          class_mode= 'categorical')\n",
        "\n",
        "\n",
        "test_dataset = test.flow_from_directory(\"/content/test\",\n",
        "                                          target_size= (150, 150),\n",
        "                                          batch_size= 32,\n",
        "                                          class_mode= 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "# 데이터 경로 설정\n",
        "dataset_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "\n",
        "# 데이터 전처리 및 증강\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2)  # 20%를 검증 데이터로 사용\n",
        "\n",
        "# 학습 데이터 생성기\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training')  # 학습 데이터\n",
        "\n",
        "# 검증 데이터 생성기\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')  # 검증 데이터\n",
        "\n",
        "# 클래스 확인\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# 사전 학습된 VGG16 모델 로드 (include_top=False로 최종 레이어 제외)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# 새로운 레이어 추가\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 사전 학습된 레이어 고정\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 학습률 감소 콜백\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=25,\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "\n",
        "# 모델 평가\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print(f\"Test accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# 모델 저장\n",
        "model.save('game_category_classifier_vgg16.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP4kx3779h9t",
        "outputId": "25f098f9-c35a-4177-ecb7-366fd92eca9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Found 2365 images belonging to 7 classes.\n",
            "Found 587 images belonging to 7 classes.\n",
            "Class indices: {'RPG': 0, '러닝': 1, '시뮬레이션': 2, '전략': 3, '퀴즈': 4, '퍼즐': 5, '하이퍼캐주얼': 6}\n",
            "Number of classes: 7\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "73/73 [==============================] - 820s 11s/step - loss: 1.8413 - accuracy: 0.2773 - val_loss: 1.6730 - val_accuracy: 0.3663 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "73/73 [==============================] - 853s 12s/step - loss: 1.6666 - accuracy: 0.3511 - val_loss: 1.5924 - val_accuracy: 0.3819 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "73/73 [==============================] - 800s 11s/step - loss: 1.6159 - accuracy: 0.3639 - val_loss: 1.5652 - val_accuracy: 0.4028 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "43/73 [================>.............] - ETA: 4:25 - loss: 1.5624 - accuracy: 0.4108"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tB7Vqa-r-6rx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}